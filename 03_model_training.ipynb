{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 环状RNA组织表达预测 - 模型训练与比较\n",
    "\n",
    "本notebook用于训练和比较多种机器学习模型，包括：\n",
    "1. 数据加载\n",
    "2. 基线模型训练\n",
    "3. 高级模型训练（随机森林、XGBoost、LightGBM、CatBoost）\n",
    "4. 模型性能比较\n",
    "5. 超参数优化\n",
    "6. 模型集成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import pickle\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# 机器学习库\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 梯度提升库\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "try:\n",
    "    import catboost as cb\n",
    "    CATBOOST_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"CatBoost not available, will skip CatBoost models\")\n",
    "    CATBOOST_AVAILABLE = False\n",
    "\n",
    "# 模型评估\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# 设置显示选项\n",
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置随机种子\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# 设置图形样式\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载处理后的数据\n",
    "with open('processed_data.pkl', 'rb') as f:\n",
    "    processed_data = pickle.load(f)\n",
    "\n",
    "# 提取数据\n",
    "X_train = processed_data['X_train']\n",
    "X_test = processed_data['X_test']\n",
    "y_train = processed_data['y_train']\n",
    "X_train_split = processed_data['X_train_split']\n",
    "X_val_split = processed_data['X_val_split']\n",
    "y_train_split = processed_data['y_train_split']\n",
    "y_val_split = processed_data['y_val_split']\n",
    "feature_names = processed_data['feature_names']\n",
    "feature_importance_df = processed_data['feature_importance']\n",
    "test_ids = processed_data['test_ids']\n",
    "\n",
    "print(f\"数据加载完成:\")\n",
    "print(f\"训练集: {X_train.shape}\")\n",
    "print(f\"测试集: {X_test.shape}\")\n",
    "print(f\"训练分割: {X_train_split.shape}\")\n",
    "print(f\"验证分割: {X_val_split.shape}\")\n",
    "print(f\"特征数量: {len(feature_names)}\")\n",
    "print(f\"类别数量: {len(np.unique(y_train))}\")\n",
    "\n",
    "# 类别分布\n",
    "print(f\"\\n类别分布:\")\n",
    "class_counts = pd.Series(y_train).value_counts().sort_index()\n",
    "for i, count in enumerate(class_counts):\n",
    "    print(f\"  类别 {i}: {count} 样本 ({count/len(y_train)*100:.1f}%)\")\n",
    "\n",
    "# 加载预处理器\n",
    "with open('preprocessors.pkl', 'rb') as f:\n",
    "    preprocessors = pickle.load(f)\n",
    "\n",
    "target_encoder = preprocessors['encoders']['target']\n",
    "print(f\"\\n目标类别: {target_encoder.classes_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 模型定义和配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义评估函数\n",
    "def evaluate_model(model, X_train, y_train, X_val, y_val, model_name):\n",
    "    \"\"\"评估模型性能\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 训练模型\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 预测\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    \n",
    "    # 计算指标\n",
    "    train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "    val_accuracy = accuracy_score(y_val, y_pred_val)\n",
    "    \n",
    "    train_f1_macro = f1_score(y_train, y_pred_train, average='macro')\n",
    "    val_f1_macro = f1_score(y_val, y_pred_val, average='macro')\n",
    "    \n",
    "    train_f1_micro = f1_score(y_train, y_pred_train, average='micro')\n",
    "    val_f1_micro = f1_score(y_val, y_pred_val, average='micro')\n",
    "    \n",
    "    train_f1_weighted = f1_score(y_train, y_pred_train, average='weighted')\n",
    "    val_f1_weighted = f1_score(y_val, y_pred_val, average='weighted')\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    results = {\n",
    "        'model_name': model_name,\n",
    "        'model': model,\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'val_accuracy': val_accuracy,\n",
    "        'train_f1_macro': train_f1_macro,\n",
    "        'val_f1_macro': val_f1_macro,\n",
    "        'train_f1_micro': train_f1_micro,\n",
    "        'val_f1_micro': val_f1_micro,\n",
    "        'train_f1_weighted': train_f1_weighted,\n",
    "        'val_f1_weighted': val_f1_weighted,\n",
    "        'training_time': training_time,\n",
    "        'y_pred_val': y_pred_val\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 交叉验证评估函数\n",
    "def cross_validate_model(model, X, y, cv=5, scoring='f1_macro'):\n",
    "    \"\"\"使用交叉验证评估模型\"\"\"\n",
    "    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=RANDOM_STATE)\n",
    "    scores = cross_val_score(model, X, y, cv=skf, scoring=scoring, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "print(\"模型评估函数定义完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 基线模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义基线模型\n",
    "baseline_models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=RANDOM_STATE, max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'SVM (RBF)': SVC(random_state=RANDOM_STATE, probability=True)\n",
    "}\n",
    "\n",
    "# 训练和评估基线模型\n",
    "baseline_results = []\n",
    "\n",
    "print(\"训练基线模型...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for name, model in baseline_models.items():\n",
    "    print(f\"训练 {name}...\")\n",
    "    \n",
    "    try:\n",
    "        result = evaluate_model(model, X_train_split, y_train_split, \n",
    "                               X_val_split, y_val_split, name)\n",
    "        baseline_results.append(result)\n",
    "        \n",
    "        print(f\"  验证集准确率: {result['val_accuracy']:.4f}\")\n",
    "        print(f\"  验证集Macro-F1: {result['val_f1_macro']:.4f}\")\n",
    "        print(f\"  训练时间: {result['training_time']:.2f}秒\")\n",
    "        print()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  错误: {str(e)}\")\n",
    "        print()\n",
    "\n",
    "print(\"基线模型训练完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 高级模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义高级模型\n",
    "advanced_models = {\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'Extra Trees': ExtraTreesClassifier(\n",
    "        n_estimators=100,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'XGBoost': xgb.XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        random_state=RANDOM_STATE,\n",
    "        eval_metric='mlogloss',\n",
    "        verbosity=0\n",
    "    ),\n",
    "    'LightGBM': lgb.LGBMClassifier(\n",
    "        n_estimators=100,\n",
    "        random_state=RANDOM_STATE,\n",
    "        verbosity=-1\n",
    "    )\n",
    "}\n",
    "\n",
    "# 如果CatBoost可用，添加到模型列表\n",
    "if CATBOOST_AVAILABLE:\n",
    "    advanced_models['CatBoost'] = cb.CatBoostClassifier(\n",
    "        iterations=100,\n",
    "        random_state=RANDOM_STATE,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "# 训练和评估高级模型\n",
    "advanced_results = []\n",
    "\n",
    "print(\"训练高级模型...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for name, model in advanced_models.items():\n",
    "    print(f\"训练 {name}...\")\n",
    "    \n",
    "    try:\n",
    "        result = evaluate_model(model, X_train_split, y_train_split, \n",
    "                               X_val_split, y_val_split, name)\n",
    "        advanced_results.append(result)\n",
    "        \n",
    "        print(f\"  验证集准确率: {result['val_accuracy']:.4f}\")\n",
    "        print(f\"  验证集Macro-F1: {result['val_f1_macro']:.4f}\")\n",
    "        print(f\"  训练时间: {result['training_time']:.2f}秒\")\n",
    "        print()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  错误: {str(e)}\")\n",
    "        print()\n",
    "\n",
    "print(\"高级模型训练完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 模型性能比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并所有结果\n",
    "all_results = baseline_results + advanced_results\n",
    "\n",
    "# 创建结果DataFrame\n",
    "results_df = pd.DataFrame([\n",
    "    {\n",
    "        'Model': result['model_name'],\n",
    "        'Train_Accuracy': result['train_accuracy'],\n",
    "        'Val_Accuracy': result['val_accuracy'],\n",
    "        'Train_F1_Macro': result['train_f1_macro'],\n",
    "        'Val_F1_Macro': result['val_f1_macro'],\n",
    "        'Train_F1_Weighted': result['train_f1_weighted'],\n",
    "        'Val_F1_Weighted': result['val_f1_weighted'],\n",
    "        'Training_Time': result['training_time'],\n",
    "        'Overfitting': result['train_f1_macro'] - result['val_f1_macro']\n",
    "    }\n",
    "    for result in all_results\n",
    "])\n",
    "\n",
    "# 按验证集Macro-F1排序\n",
    "results_df = results_df.sort_values('Val_F1_Macro', ascending=False)\n",
    "\n",
    "print(\"模型性能比较 (按验证集Macro-F1排序):\")\n",
    "print(\"=\" * 100)\n",
    "display(results_df.round(4))\n",
    "\n",
    "# 找到最佳模型\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "best_result = next(r for r in all_results if r['model_name'] == best_model_name)\n",
    "\n",
    "print(f\"\\n最佳模型: {best_model_name}\")\n",
    "print(f\"验证集Macro-F1: {best_result['val_f1_macro']:.4f}\")\n",
    "print(f\"验证集准确率: {best_result['val_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化模型性能比较\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Macro-F1分数比较\n",
    "ax1 = axes[0, 0]\n",
    "x_pos = np.arange(len(results_df))\n",
    "ax1.bar(x_pos - 0.2, results_df['Train_F1_Macro'], 0.4, label='Train', alpha=0.8)\n",
    "ax1.bar(x_pos + 0.2, results_df['Val_F1_Macro'], 0.4, label='Validation', alpha=0.8)\n",
    "ax1.set_xlabel('Models')\n",
    "ax1.set_ylabel('Macro-F1 Score')\n",
    "ax1.set_title('Macro-F1 Score Comparison')\n",
    "ax1.set_xticks(x_pos)\n",
    "ax1.set_xticklabels(results_df['Model'], rotation=45, ha='right')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. 准确率比较\n",
    "ax2 = axes[0, 1]\n",
    "ax2.bar(x_pos - 0.2, results_df['Train_Accuracy'], 0.4, label='Train', alpha=0.8)\n",
    "ax2.bar(x_pos + 0.2, results_df['Val_Accuracy'], 0.4, label='Validation', alpha=0.8)\n",
    "ax2.set_xlabel('Models')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title('Accuracy Comparison')\n",
    "ax2.set_xticks(x_pos)\n",
    "ax2.set_xticklabels(results_df['Model'], rotation=45, ha='right')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. 训练时间比较\n",
    "ax3 = axes[1, 0]\n",
    "ax3.bar(x_pos, results_df['Training_Time'], alpha=0.8)\n",
    "ax3.set_xlabel('Models')\n",
    "ax3.set_ylabel('Training Time (seconds)')\n",
    "ax3.set_title('Training Time Comparison')\n",
    "ax3.set_xticks(x_pos)\n",
    "ax3.set_xticklabels(results_df['Model'], rotation=45, ha='right')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. 过拟合程度\n",
    "ax4 = axes[1, 1]\n",
    "colors = ['red' if x > 0.05 else 'green' for x in results_df['Overfitting']]\n",
    "ax4.bar(x_pos, results_df['Overfitting'], alpha=0.8, color=colors)\n",
    "ax4.set_xlabel('Models')\n",
    "ax4.set_ylabel('Overfitting (Train F1 - Val F1)')\n",
    "ax4.set_title('Overfitting Analysis')\n",
    "ax4.set_xticks(x_pos)\n",
    "ax4.set_xticklabels(results_df['Model'], rotation=45, ha='right')\n",
    "ax4.axhline(y=0.05, color='red', linestyle='--', alpha=0.7, label='Overfitting Threshold')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 交叉验证评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对表现最好的几个模型进行交叉验证\n",
    "top_models = results_df.head(3)['Model'].tolist()\n",
    "\n",
    "print(\"对Top 3模型进行5折交叉验证...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "cv_results = {}\n",
    "\n",
    "for model_name in top_models:\n",
    "    # 找到对应的模型\n",
    "    model_result = next(r for r in all_results if r['model_name'] == model_name)\n",
    "    model = model_result['model']\n",
    "    \n",
    "    print(f\"交叉验证 {model_name}...\")\n",
    "    \n",
    "    # 进行交叉验证\n",
    "    cv_scores = cross_validate_model(model, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "    \n",
    "    cv_results[model_name] = {\n",
    "        'scores': cv_scores,\n",
    "        'mean': cv_scores.mean(),\n",
    "        'std': cv_scores.std()\n",
    "    }\n",
    "    \n",
    "    print(f\"  CV Macro-F1: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "    print(f\"  各折分数: {[f'{score:.4f}' for score in cv_scores]}\")\n",
    "    print()\n",
    "\n",
    "# 可视化交叉验证结果\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "model_names = list(cv_results.keys())\n",
    "means = [cv_results[name]['mean'] for name in model_names]\n",
    "stds = [cv_results[name]['std'] for name in model_names]\n",
    "\n",
    "x_pos = np.arange(len(model_names))\n",
    "plt.bar(x_pos, means, yerr=stds, capsize=5, alpha=0.8)\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Cross-Validation Macro-F1 Score')\n",
    "plt.title('5-Fold Cross-Validation Results')\n",
    "plt.xticks(x_pos, model_names)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 添加数值标签\n",
    "for i, (mean, std) in enumerate(zip(means, stds)):\n",
    "    plt.text(i, mean + std + 0.005, f'{mean:.4f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 确定最终最佳模型\n",
    "best_cv_model = max(cv_results.keys(), key=lambda x: cv_results[x]['mean'])\n",
    "print(f\"\\n交叉验证最佳模型: {best_cv_model}\")\n",
    "print(f\"CV Macro-F1: {cv_results[best_cv_model]['mean']:.4f} (+/- {cv_results[best_cv_model]['std'] * 2:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 超参数优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对最佳模型进行超参数优化\n",
    "print(f\"对 {best_cv_model} 进行超参数优化...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 定义超参数搜索空间\n",
    "param_grids = {\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [10, 20, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'max_features': ['sqrt', 'log2']\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 6, 9],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'subsample': [0.8, 0.9, 1.0],\n",
    "        'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 6, 9],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'num_leaves': [31, 50, 100],\n",
    "        'subsample': [0.8, 0.9, 1.0]\n",
    "    }\n",
    "}\n",
    "\n",
    "if CATBOOST_AVAILABLE:\n",
    "    param_grids['CatBoost'] = {\n",
    "        'iterations': [100, 200, 300],\n",
    "        'depth': [4, 6, 8],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'l2_leaf_reg': [1, 3, 5]\n",
    "    }\n",
    "\n",
    "# 获取最佳模型的基础版本\n",
    "if best_cv_model == 'Random Forest':\n",
    "    base_model = RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1)\n",
    "elif best_cv_model == 'XGBoost':\n",
    "    base_model = xgb.XGBClassifier(random_state=RANDOM_STATE, eval_metric='mlogloss', verbosity=0)\n",
    "elif best_cv_model == 'LightGBM':\n",
    "    base_model = lgb.LGBMClassifier(random_state=RANDOM_STATE, verbosity=-1)\n",
    "elif best_cv_model == 'CatBoost' and CATBOOST_AVAILABLE:\n",
    "    base_model = cb.CatBoostClassifier(random_state=RANDOM_STATE, verbose=False)\n",
    "else:\n",
    "    # 如果最佳模型不在优化列表中，使用Random Forest\n",
    "    best_cv_model = 'Random Forest'\n",
    "    base_model = RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1)\n",
    "\n",
    "# 使用RandomizedSearchCV进行超参数搜索\n",
    "param_grid = param_grids[best_cv_model]\n",
    "\n",
    "print(f\"搜索空间大小: {np.prod([len(v) for v in param_grid.values()])} 种组合\")\n",
    "print(f\"使用随机搜索，尝试 50 种组合...\\n\")\n",
    "\n",
    "# 设置交叉验证\n",
    "cv_strategy = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# 执行随机搜索\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=base_model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=50,\n",
    "    cv=cv_strategy,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1,\n",
    "    random_state=RANDOM_STATE,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "random_search.fit(X_train, y_train)\n",
    "search_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n超参数搜索完成，耗时: {search_time:.2f}秒\")\n",
    "print(f\"最佳CV分数: {random_search.best_score_:.4f}\")\n",
    "print(f\"最佳参数: {random_search.best_params_}\")\n",
    "\n",
    "# 获取优化后的模型\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# 在验证集上评估优化后的模型\n",
    "optimized_result = evaluate_model(best_model, X_train_split, y_train_split, \n",
    "                                 X_val_split, y_val_split, f'{best_cv_model} (Optimized)')\n",
    "\n",
    "print(f\"\\n优化后模型性能:\")\n",
    "print(f\"验证集Macro-F1: {optimized_result['val_f1_macro']:.4f}\")\n",
    "print(f\"验证集准确率: {optimized_result['val_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 模型集成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建集成模型\n",
    "print(\"创建集成模型...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 选择表现最好的几个模型进行集成\n",
    "ensemble_models = []\n",
    "\n",
    "# 添加优化后的最佳模型\n",
    "ensemble_models.append((f'{best_cv_model}_optimized', best_model))\n",
    "\n",
    "# 添加其他表现良好的模型\n",
    "for result in all_results:\n",
    "    if result['model_name'] != best_cv_model and result['val_f1_macro'] > 0.7:  # 阈值可调整\n",
    "        ensemble_models.append((result['model_name'], result['model']))\n",
    "\n",
    "print(f\"集成模型包含 {len(ensemble_models)} 个基模型:\")\n",
    "for name, _ in ensemble_models:\n",
    "    print(f\"  - {name}\")\n",
    "\n",
    "if len(ensemble_models) >= 2:\n",
    "    # 创建投票分类器\n",
    "    voting_classifier = VotingClassifier(\n",
    "        estimators=ensemble_models,\n",
    "        voting='soft'  # 使用概率投票\n",
    "    )\n",
    "    \n",
    "    # 评估集成模型\n",
    "    ensemble_result = evaluate_model(voting_classifier, X_train_split, y_train_split, \n",
    "                                    X_val_split, y_val_split, 'Ensemble (Voting)')\n",
    "    \n",
    "    print(f\"\\n集成模型性能:\")\n",
    "    print(f\"验证集Macro-F1: {ensemble_result['val_f1_macro']:.4f}\")\n",
    "    print(f\"验证集准确率: {ensemble_result['val_accuracy']:.4f}\")\n",
    "    \n",
    "    # 比较单模型和集成模型\n",
    "    print(f\"\\n性能提升:\")\n",
    "    improvement = ensemble_result['val_f1_macro'] - optimized_result['val_f1_macro']\n",
    "    print(f\"Macro-F1提升: {improvement:.4f} ({improvement/optimized_result['val_f1_macro']*100:.2f}%)\")\n",
    "    \n",
    "    # 选择最终模型\n",
    "    if ensemble_result['val_f1_macro'] > optimized_result['val_f1_macro']:\n",
    "        final_model = voting_classifier\n",
    "        final_model_name = 'Ensemble (Voting)'\n",
    "        final_score = ensemble_result['val_f1_macro']\n",
    "        print(f\"\\n选择集成模型作为最终模型\")\n",
    "    else:\n",
    "        final_model = best_model\n",
    "        final_model_name = f'{best_cv_model} (Optimized)'\n",
    "        final_score = optimized_result['val_f1_macro']\n",
    "        print(f\"\\n选择优化后的单模型作为最终模型\")\n",
    "else:\n",
    "    print(\"\\n只有一个高性能模型，跳过集成\")\n",
    "    final_model = best_model\n",
    "    final_model_name = f'{best_cv_model} (Optimized)'\n",
    "    final_score = optimized_result['val_f1_macro']\n",
    "\n",
    "print(f\"\\n最终模型: {final_model_name}\")\n",
    "print(f\"最终验证集Macro-F1: {final_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 保存模型和结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在完整训练集上重新训练最终模型\n",
    "print(\"在完整训练集上重新训练最终模型...\")\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# 保存最终模型\n",
    "model_data = {\n",
    "    'model': final_model,\n",
    "    'model_name': final_model_name,\n",
    "    'validation_score': final_score,\n",
    "    'feature_names': feature_names,\n",
    "    'target_encoder': target_encoder,\n",
    "    'training_timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "}\n",
    "\n",
    "with open('final_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model_data, f)\n",
    "\n",
    "# 保存训练结果\n",
    "training_results = {\n",
    "    'all_results': results_df,\n",
    "    'cv_results': cv_results,\n",
    "    'best_params': random_search.best_params_ if 'random_search' in locals() else None,\n",
    "    'final_model_name': final_model_name,\n",
    "    'final_score': final_score\n",
    "}\n",
    "\n",
    "with open('training_results.pkl', 'wb') as f:\n",
    "    pickle.dump(training_results, f)\n",
    "\n",
    "# 保存结果到CSV\n",
    "results_df.to_csv('model_comparison.csv', index=False)\n",
    "\n",
    "print(\"模型和结果已保存到:\")\n",
    "print(\"- final_model.pkl\")\n",
    "print(\"- training_results.pkl\")\n",
    "print(\"- model_comparison.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 训练总结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练总结报告\n",
    "print(\"=\" * 80)\n",
    "print(\"                    模型训练总结报告\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"1. 数据概况:\")\n",
    "print(f\"   - 训练样本数: {X_train.shape[0]}\")\n",
    "print(f\"   - 特征数量: {X_train.shape[1]}\")\n",
    "print(f\"   - 类别数量: {len(np.unique(y_train))}\")\n",
    "print(f\"   - 目标类别: {target_encoder.classes_}\")\n",
    "\n",
    "print(f\"2. 模型训练:\")\n",
    "print(f\"   - 训练模型数量: {len(all_results)}\")\n",
    "print(f\"   - 基线模型: {len(baseline_results)} 个\")\n",
    "print(f\"   - 高级模型: {len(advanced_results)} 个\")\n",
    "\n",
    "print(f\"3. 性能排行 (Top 5):\")\n",
    "for i, (_, row) in enumerate(results_df.head(5).iterrows(), 1):\n",
    "    print(f\"   {i}. {row['Model']:20s} - Macro-F1: {row['Val_F1_Macro']:.4f}\")\n",
    "\n",
    "print(f\"4. 最终模型:\")\n",
    "print(f\"   - 模型名称: {final_model_name}\")\n",
    "print(f\"   - 验证集Macro-F1: {final_score:.4f}\")\n",
    "if 'random_search' in locals():\n",
    "    print(f\"   - 最佳参数: {random_search.best_params_}\")\n",
    "\n",
    "print(f\"5. 下一步:\")\n",
    "print(f\"   - 进行详细的模型评估和分析\")\n",
    "print(f\"   - 生成测试集预测结果\")\n",
    "print(f\"   - 创建提交文件\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}